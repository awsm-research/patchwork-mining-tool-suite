{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130d1e79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import DuplicateKeyError, CollectionInvalid\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad64890b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = ['kernel', 'ozlabs', 'ffmpeg']\n",
    "CATEGORY = ['projects', 'series', 'patches']\n",
    "INVALID_PAGE = {\n",
    "    \"detail\": \"Invalid page.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d05106",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_database(username, password, database_name):\n",
    "    # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "    CONNECTION_STRING = f\"mongodb+srv://{username}:{password}@cluster0.hls0ye8.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "    # Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
    "    client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "    # Create the database for our example (we will use the same database throughout the tutorial\n",
    "    return client[database_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277d5320",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the database\n",
    "username = 'default'\n",
    "password = 'comp90055codereview'\n",
    "database_name = 'code_review'\n",
    "db = get_database(username, password, database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c16bf0-18e9-4a8e-b715-3e8a755f18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop collections\n",
    "# try:\n",
    "#     db['project'].drop()\n",
    "#     db['series'].drop()\n",
    "#     db['patch'].drop()\n",
    "#     db['comment'].drop()\n",
    "#     db['account'].drop()\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d442423",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account', 'comment', 'project', 'patch', 'series']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    project = db.create_collection('project')\n",
    "    series = db.create_collection('series')\n",
    "    patch = db.create_collection('patch')\n",
    "    comment = db.create_collection('comment')\n",
    "    account = db.create_collection('account')\n",
    "except CollectionInvalid:\n",
    "    pass\n",
    "    # project = db['project']\n",
    "    # series = db['series']\n",
    "    # patch = db['patch']\n",
    "    # comment = db['comment']\n",
    "    # account = db['account']\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215d56f7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original_id_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.create_index([(\"original_id\", pymongo.ASCENDING)],unique=True)\n",
    "series.create_index([(\"original_id\", pymongo.ASCENDING)],unique=True)\n",
    "patch.create_index([(\"original_id\", pymongo.ASCENDING)],unique=True)\n",
    "comment.create_index([(\"original_id\", pymongo.ASCENDING)],unique=True)\n",
    "account.create_index([(\"original_id\", pymongo.ASCENDING)],unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0160aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def collection_insert_one(collection, item):\n",
    "    try:\n",
    "        collection.insert_one(item)\n",
    "    except DuplicateKeyError:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e442f28-a3df-44ec-bcf2-7c3ea8563756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# t_url = 'https://patchwork.ffmpeg.org/api/patches/17384/'\n",
    "# response = requests.get(t_url).json()\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b0f501-ca9c-4cd9-911b-3c6d1553fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_id, api_url, name, web_url = retrieve_basic_info(response['submitter'])\n",
    "# print(api_id, api_url, name, web_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d6791f-3dd5-4c60-8259-b8820e726133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_basic_info(json):\n",
    "    api_id = 'id'\n",
    "    api_url = 'url'\n",
    "    name = 'name'\n",
    "    web_url = 'web_url'\n",
    "    \n",
    "    info = [api_id, api_url, name, web_url]\n",
    "    \n",
    "    for i in range(len(info)):\n",
    "        try:\n",
    "            info[i] = json[info[i]]\n",
    "        except KeyError:\n",
    "            info[i] = None\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f9df41-771d-402d-910b-1f62865222b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# string = 'https://patchwork.ffmpeg.org/api/projects/'\n",
    "\n",
    "# try:\n",
    "#     found = re.search('https://patchwork\\.(.*?)\\.org', string).group(1)\n",
    "#     print(found)\n",
    "# except AttributeError:\n",
    "#     print('error')\n",
    "\n",
    "# 'A'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9220955",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_project_data(endpoint_name, json_project, database):\n",
    "    # print(f\"retrieving project: {json_project['url']}\")\n",
    "    # project info\n",
    "    project_api_id, project_api_url, project_name, project_web_url = retrieve_basic_info(json_project)\n",
    "    \n",
    "    project_repo_url = json_project['webscm_url']\n",
    "    project_list_id = json_project['list_id']\n",
    "    project_list_address = json_project['list_email']\n",
    "    project_original_id = '-'.join([endpoint_name, 'project', str(project_api_id)])\n",
    "\n",
    "    # maintainer_info\n",
    "    maintainers = json_project['maintainers']\n",
    "    maintainer_list = list()\n",
    "    for maintainer in maintainers:\n",
    "        \n",
    "        maintainer_api_id, maintainer_api_url, _, _ = retrieve_basic_info(maintainer)\n",
    "        maintainer_username = maintainer['username']\n",
    "        maintainer_email = maintainer['email']\n",
    "        maintainer_original_id = '-'.join([endpoint_name, 'people', str(maintainer_api_id)])\n",
    "\n",
    "        maintainer_list.append(maintainer_original_id)\n",
    "\n",
    "        item_account = {\n",
    "            'original_id': maintainer_original_id,\n",
    "            'email': maintainer_email,\n",
    "            'username': maintainer_username,\n",
    "            'api_url': maintainer_api_url\n",
    "        }\n",
    "\n",
    "        collection_insert_one(database['account'], item_account)\n",
    "\n",
    "    item_project = {\n",
    "        'original_id': project_original_id,\n",
    "        'name': project_name,\n",
    "        'repo_url': project_repo_url,\n",
    "        'list_id': project_list_id,\n",
    "        'list_address': project_list_address,\n",
    "        'web_url': project_web_url,\n",
    "        'api_url': project_api_url,\n",
    "        'maintainers': maintainer_list\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['project'], item_project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c418792",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_series_data(endpoint_name, json_series, database):\n",
    "    # print(f\"retrieving series: {json_series['url']}\")\n",
    "    # series info\n",
    "    series_api_id, series_api_url, series_name, series_web_url = retrieve_basic_info(json_series)\n",
    "    series_created_date = parser.parse(json_series['date'])\n",
    "    series_version = json_series['version']\n",
    "    series_total = json_series['total']\n",
    "    series_received_total = json_series['received_total']\n",
    "    \n",
    "    series_project_api_id, _, series_project_name, _ = retrieve_basic_info(json_series['project'])\n",
    "    project_original_id = '-'.join([endpoint_name, 'project', str(series_project_api_id)])\n",
    "    series_original_id = '-'.join([endpoint_name, 'series', str(series_api_id)])\n",
    "\n",
    "    #get cover letter content\n",
    "    if json_series['cover_letter']:\n",
    "        cover_letter_url = json_series['cover_letter']['url']\n",
    "        cover_detail = requests.get(cover_letter_url).json()\n",
    "        # series_cover_letter_content = deactivate_quote(cover_detail['content'])\n",
    "        series_cover_letter_content = cover_detail['content']\n",
    "    else:\n",
    "        series_cover_letter_content = ''\n",
    "\n",
    "    # get project id\n",
    "    # series_proj_original_id = json_series['project']['url'][:-1]\n",
    "\n",
    "    # submitter info\n",
    "    series_submitter_api_id, series_submitter_api_url, _, _ = retrieve_basic_info(json_series['submitter'])\n",
    "    series_submitter_original_id = '-'.join([endpoint_name, 'people', str(series_submitter_api_id)])\n",
    "    series_submitter_email = json_series['submitter']['email']\n",
    "    series_submitter_name = json_series['submitter']['name']\n",
    "\n",
    "    item_account = {\n",
    "        'original_id': series_submitter_original_id,\n",
    "        'email': series_submitter_email,\n",
    "        'username': series_submitter_name,\n",
    "        'api_url': series_submitter_api_url\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['account'], item_account)\n",
    "\n",
    "    item_series = {\n",
    "        'original_id': series_original_id,\n",
    "        'name': series_name,\n",
    "        'created_date': series_created_date,\n",
    "        'version': series_version,\n",
    "        'total': series_total,\n",
    "        'received_total': series_received_total,\n",
    "        'cover_letter_content': series_cover_letter_content,\n",
    "        'project_original_id': project_original_id,\n",
    "        'submitter_account_original_id': series_submitter_original_id,\n",
    "        'web_url': series_web_url,\n",
    "        'api_url': series_api_url\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['series'], item_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "051fc4b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_comment_data(endpoint_name, json_comment, project_original_id, patch_original_id, database):\n",
    "    # print(f\"retrieving comment, id: {json_comment['web_url']}\")\n",
    "    #comment info\n",
    "    comment_api_id = json_comment['id']\n",
    "    comment_original_id = '-'.join([endpoint_name, 'comment', str(comment_api_id)])\n",
    "    comment_web_url = json_comment['web_url']\n",
    "    comment_msg_id = json_comment['msgid']\n",
    "    comment_msg_content = json_comment['content']\n",
    "    comment_date = parser.parse(json_comment['date'])\n",
    "    comment_subject = json_comment['subject']\n",
    "    comment_reply_to_msg_id = ''\n",
    "    if 'In-Reply-To' in json_comment['headers'].keys():\n",
    "        in_reply_to = json_comment['headers']['In-Reply-To']\n",
    "        if in_reply_to[:2] == '\\n ':\n",
    "            comment_reply_to_msg_id = in_reply_to[2:]\n",
    "\n",
    "    # get submitter account id\n",
    "    # insert account if not exist\n",
    "    comment_submitter_api_id, comment_submitter_api_url, _, _ = retrieve_basic_info(json_comment['submitter'])\n",
    "    comment_submitter_original_id = '-'.join([endpoint_name, 'people', str(comment_submitter_api_id)])\n",
    "    comment_submitter_username = json_comment['submitter']['name']\n",
    "    comment_submitter_email = json_comment['submitter']['email']\n",
    "\n",
    "    item_account = {\n",
    "        'original_id': comment_submitter_original_id,\n",
    "        'email': comment_submitter_email,\n",
    "        'username': comment_submitter_username,\n",
    "        'api_url': comment_submitter_api_url\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['account'], item_account)\n",
    "\n",
    "    item_comment = {\n",
    "        'original_id': comment_original_id,\n",
    "        'msg_id': comment_msg_id,\n",
    "        'msg_content': comment_msg_content,\n",
    "        'date': comment_date,\n",
    "        'subject': comment_subject,\n",
    "        'in_reply_to': comment_reply_to_msg_id,\n",
    "        'project_original_id': project_original_id,\n",
    "        'patch_original_id': patch_original_id,\n",
    "        'submitter_account_original_id': comment_submitter_original_id,\n",
    "        'change_id': '',\n",
    "        'mailing_list_id': '',\n",
    "        'web_url': comment_web_url\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['comment'], item_comment)\n",
    "\n",
    "    # TODO get change id\n",
    "    # TODO get mailing list id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd6f9f53",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_patch_data(endpoint_name, json_patch, database):\n",
    "    # print(f\"retrieving patch {json_patch['url']}\")\n",
    "    #patch info\n",
    "    patch_api_id, patch_api_url, patch_name, patch_web_url = retrieve_basic_info(json_patch)\n",
    "    patch_project_original_id = '-'.join([endpoint_name, 'project', str(json_patch['project']['id'])])\n",
    "    patch_original_id = '-'.join([endpoint_name, 'patch', str(patch_api_id)])\n",
    "    \n",
    "    patch_state = json_patch['state']\n",
    "    patch_date = parser.parse(json_patch['date'])\n",
    "    patch_msg_id = json_patch['msgid']\n",
    "    patch_msg_content = json_patch['content']\n",
    "    patch_code_diff = json_patch['diff']\n",
    "\n",
    "    # TODO get change id\n",
    "    # TODO get mailing list id\n",
    "\n",
    "    # get series id\n",
    "    if json_patch['series']:\n",
    "        patch_series_api_id = json_patch['series']['id']\n",
    "        patch_series_original_id = '-'.join([endpoint_name, 'series', str(patch_series_api_id)])\n",
    "    else:\n",
    "        patch_series_original_id = ''\n",
    "\n",
    "    # submitter info\n",
    "    patch_submitter_api_id, patch_submitter_api_url, _, _ = retrieve_basic_info(json_patch['submitter'])\n",
    "    patch_submitter_original_id = '-'.join([endpoint_name, 'people', str(patch_submitter_api_id)])\n",
    "    patch_submitter_username = json_patch['submitter']['name']\n",
    "    patch_submitter_email = json_patch['submitter']['email']\n",
    "\n",
    "    item_account = {\n",
    "        'original_id': patch_submitter_original_id,\n",
    "        'email': patch_submitter_email,\n",
    "        'username': patch_submitter_username,\n",
    "        'api_url': patch_submitter_api_url\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['account'], item_account)\n",
    "\n",
    "    item_patch = {\n",
    "        'original_id': patch_original_id,\n",
    "        'name': patch_name,\n",
    "        'state': patch_state,\n",
    "        'date': patch_date,\n",
    "        'msg_id': patch_msg_id,\n",
    "        'msg_content': patch_msg_content,\n",
    "        'code_diff': patch_code_diff,\n",
    "        'project_original_id': patch_project_original_id,\n",
    "        'series_original_id': patch_series_original_id,\n",
    "        'submitter_account_original_id': patch_submitter_original_id,\n",
    "        'change_id': '',\n",
    "        'mailing_list_id': '',\n",
    "        'api_url': patch_api_url,\n",
    "        'web_url': patch_web_url\n",
    "    }\n",
    "\n",
    "    collection_insert_one(database['patch'], item_patch)\n",
    "\n",
    "    comment_url = json_patch['comments']\n",
    "    comment_list = requests.get(comment_url).json()\n",
    "    if comment_list:\n",
    "        for c in comment_list:\n",
    "            retrieve_comment_data(endpoint_name, c, patch_project_original_id, patch_original_id, database)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29e29063",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def retrieved_items(collection):\n",
    "#     items = collection.find()\n",
    "#     return [item['original_id'] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41de5ea4-053f-4365-8714-c8d7ac341148",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREAD = 6\n",
    "PAGE_START = 0\n",
    "BATCH = 250\n",
    "\n",
    "def main_func(api_url_base, endpoint_name, database, entity_type, thread_no):\n",
    "    page_num = PAGE_START + thread_no\n",
    "    response = requests.get(api_url_base %(endpoint_name, entity_type, page_num)).json()\n",
    "\n",
    "    retrieval_func = {\n",
    "        'projects': retrieve_project_data,\n",
    "        'series': retrieve_series_data,\n",
    "        'patches': retrieve_patch_data\n",
    "    }\n",
    "\n",
    "    while response != INVALID_PAGE and page_num <= PAGE_START + BATCH:\n",
    "        # print('%s: page%d started' %entity_type)\n",
    "        p_start_time = time.time()\n",
    "\n",
    "        for entity in response:\n",
    "            entity_api_url = entity['url']\n",
    "            entity_detail = requests.get(entity_api_url).json()\n",
    "\n",
    "            retrieval_func[entity_type](endpoint_name, entity_detail, database)\n",
    "        \n",
    "        total_time = time.time() - p_start_time\n",
    "        print('%s:\\tpage%d\\tcompleted in %.2f s' %(entity_type, page_num, total_time))\n",
    "\n",
    "        page_num += MAX_THREAD\n",
    "        response = requests.get(api_url_base %(endpoint_name, entity_type, page_num)).json()\n",
    "\n",
    "def crawl_entity(api_url_base, endpoint_name, database, entity_type):\n",
    "    # page_num = 1\n",
    "    # api_url = api_url_base %(endpoint_name, entity_type, page_num)\n",
    "    # thread1 = Thread(target=main_func, args=(api_url_base, endpoint_name, database, entity_type, 1))\n",
    "    # thread2 = Thread(target=main_func, args=(api_url_base, endpoint_name, database, entity_type, 2))\n",
    "    \n",
    "    # thread1.start()\n",
    "    # thread2.start()\n",
    "    \n",
    "    threads = [Thread(target=main_func, args=(api_url_base, endpoint_name, database, entity_type, thread_no)) for thread_no in range(1, MAX_THREAD + 1)]\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    # main_func(api_url_base, endpoint_name, database, entity_type, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c21dcf7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def crawl_data(endpoint_name, database):\n",
    "    start_time = time.time()\n",
    "    api_url_base = 'https://patchwork.%s.org/api/%s/?page=%d'\n",
    "    entity_types = ['projects', 'series', 'patches']\n",
    "    # entity_types = ['series']\n",
    "    \n",
    "#     threads = [Thread(target=crawl_entity, args=(api_url_base, endpoint_name, database, entity_type)) for entity_type in entity_types]\n",
    "    \n",
    "#     for thread in threads:\n",
    "#         thread.start()\n",
    "        \n",
    "#     for thread in threads:\n",
    "#         thread.join()\n",
    "\n",
    "    [crawl_entity(api_url_base, endpoint_name, database, entity_type) for entity_type in entity_types]\n",
    "    \n",
    "    duration = (time.time() - start_time) / 60\n",
    "    print('Retrieval completed in %.2f min' %duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8af3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects:\tpage1\tcompleted in 1.98 s\n",
      "series:\tpage2\tcompleted in 46.66 s\n",
      "series:\tpage3\tcompleted in 46.24 s\n",
      "series:\tpage1\tcompleted in 50.59 s\n",
      "series:\tpage5\tcompleted in 50.44 s\n",
      "series:\tpage6\tcompleted in 50.91 s\n",
      "series:\tpage4\tcompleted in 53.37 s\n",
      "series:\tpage8\tcompleted in 44.04 s\n",
      "series:\tpage9\tcompleted in 46.59 s\n",
      "series:\tpage11\tcompleted in 44.15 s\n",
      "series:\tpage12\tcompleted in 45.35 s\n",
      "series:\tpage7\tcompleted in 46.89 s\n",
      "series:\tpage10\tcompleted in 46.70 s\n",
      "series:\tpage14\tcompleted in 47.07 s\n",
      "series:\tpage15\tcompleted in 44.56 s\n",
      "series:\tpage18\tcompleted in 44.04 s\n",
      "series:\tpage13\tcompleted in 48.50 s\n",
      "series:\tpage17\tcompleted in 50.92 s\n",
      "series:\tpage16\tcompleted in 50.07 s\n",
      "series:\tpage20\tcompleted in 49.24 s\n",
      "series:\tpage21\tcompleted in 48.91 s\n",
      "series:\tpage24\tcompleted in 47.49 s\n",
      "series:\tpage19\tcompleted in 47.51 s\n",
      "series:\tpage23\tcompleted in 48.16 s\n",
      "series:\tpage22\tcompleted in 49.58 s\n",
      "series:\tpage26\tcompleted in 49.36 s\n",
      "series:\tpage30\tcompleted in 47.97 s\n",
      "series:\tpage27\tcompleted in 49.17 s\n",
      "series:\tpage25\tcompleted in 46.41 s\n",
      "series:\tpage29\tcompleted in 47.25 s\n",
      "series:\tpage28\tcompleted in 44.64 s\n",
      "series:\tpage32\tcompleted in 46.98 s\n",
      "series:\tpage33\tcompleted in 46.71 s\n",
      "series:\tpage36\tcompleted in 49.67 s\n",
      "series:\tpage31\tcompleted in 47.32 s\n",
      "series:\tpage35\tcompleted in 49.83 s\n",
      "series:\tpage34\tcompleted in 54.26 s\n",
      "series:\tpage39\tcompleted in 48.21 s\n",
      "series:\tpage38\tcompleted in 51.12 s\n",
      "series:\tpage42\tcompleted in 48.14 s\n",
      "series:\tpage37\tcompleted in 48.27 s\n",
      "series:\tpage41\tcompleted in 45.47 s\n",
      "series:\tpage40\tcompleted in 43.96 s\n",
      "series:\tpage45\tcompleted in 47.98 s\n",
      "series:\tpage43\tcompleted in 46.51 s\n",
      "series:\tpage44\tcompleted in 49.92 s\n",
      "series:\tpage48\tcompleted in 49.72 s\n",
      "series:\tpage47\tcompleted in 48.78 s\n",
      "series:\tpage46\tcompleted in 47.28 s\n",
      "series:\tpage51\tcompleted in 47.52 s\n",
      "series:\tpage49\tcompleted in 49.38 s\n",
      "series:\tpage50\tcompleted in 47.21 s\n",
      "series:\tpage54\tcompleted in 46.96 s\n",
      "series:\tpage53\tcompleted in 47.83 s\n",
      "series:\tpage52\tcompleted in 49.96 s\n",
      "series:\tpage57\tcompleted in 49.37 s\n",
      "series:\tpage60\tcompleted in 45.82 s\n",
      "series:\tpage55\tcompleted in 46.19 s\n",
      "series:\tpage56\tcompleted in 48.75 s\n",
      "series:\tpage59\tcompleted in 46.30 s\n",
      "series:\tpage58\tcompleted in 48.45 s\n"
     ]
    }
   ],
   "source": [
    "# for cate in CATEGORY:\n",
    "#     crawl_data(NAME[2], cate)\n",
    "crawl_data(NAME[2], db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118e28a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 0.86 min for 1 page in series\n",
    "# 0.90 min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
