{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patchwork Code Review Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pymongo\n",
    "from pymongo.cursor import Cursor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import median\n",
    "import whatthepatch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_diff(diff_text: str):\n",
    "    changed_lines = 0\n",
    "    changed_files = 0\n",
    "\n",
    "    incomplete_flag = False\n",
    "\n",
    "    try:\n",
    "        diffs = [diff for diff in whatthepatch.parse_patch(diff_text)]\n",
    "\n",
    "        changed_files = len(diffs)\n",
    "\n",
    "        # count modified lines -- lines that exist only in old or or new version\n",
    "        for diff in diffs:\n",
    "            try:\n",
    "                for change in diff.changes:\n",
    "                    if change.old is None or change.new is None:\n",
    "                        changed_lines += 1\n",
    "            except Exception:\n",
    "                # create new blank file - no changes\n",
    "                incomplete_flag = True\n",
    "                pass\n",
    "\n",
    "    except Exception:\n",
    "        # parsing error - skip\n",
    "        # e.g., https://patchwork.ozlabs.org/project/qemu-devel/patch/1643044621-15892-11-git-send-email-eric.devolder@oracle.com/\n",
    "        incomplete_flag = True\n",
    "        pass\n",
    "\n",
    "    return (changed_files, changed_lines, incomplete_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_names(project:str, level: int, cleaned=False):\n",
    "    if not cleaned:\n",
    "        return [\n",
    "            f\"data/data_{project}_change{level}.csv\",\n",
    "            f\"data/describe_{project}_change{level}.csv\"\n",
    "        ]\n",
    "    \n",
    "    return [\n",
    "        f\"output/cleaned_{project}_change{level}.csv\",\n",
    "        f\"output/cleaned_describe_{project}_change{level}.csv\"\n",
    "    ]\n",
    "    \n",
    "\n",
    "def export_dataset(patch_group_info_list: list, project: str, level: int):\n",
    "\n",
    "    patch_group_info_df = pd.DataFrame(patch_group_info_list)\n",
    "\n",
    "    data_filename, description_filename = generate_file_names(\n",
    "        project=project,\n",
    "        level=level\n",
    "    )\n",
    "\n",
    "    # raw data    \n",
    "    patch_group_info_df.to_csv(data_filename, index=False)\n",
    "\n",
    "    # project level - descriptive analysis\n",
    "    patch_group_info_df.describe(include=\"all\").to_csv(\n",
    "        description_filename\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"code_review_db\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_projects = [\n",
    "    \"ffmpeg-project-1\",\n",
    "    \"ozlabs-project-18\",\n",
    "    \"kernel-project-399\",\n",
    "    \"ozlabs-project-14\",\n",
    "    \"kernel-project-62\"  \n",
    "]\n",
    "\n",
    "project_name = {\n",
    "    \"ffmpeg-project-1\": \"ffmpeg\",\n",
    "    \"ozlabs-project-18\": \"u-boot\",\n",
    "    \"kernel-project-399\": \"netdev + bpf\",\n",
    "    \"ozlabs-project-14\": \"qemu\",\n",
    "    \"kernel-project-62\": \"arm\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_groups(level: int, project: str) -> Cursor:\n",
    "    changes_col = db[f\"patchwork_change{level}\"]\n",
    "    return changes_col.find(\n",
    "        {\"project\": project}\n",
    "    )\n",
    "\n",
    "\n",
    "def get_patches_in_group(\n",
    "    level: int,\n",
    "    patch_group: Cursor\n",
    ") -> list:\n",
    "    \n",
    "    patch_col = db[\"patchwork_patch\"]\n",
    "    patch_group_column_name = f\"change{level}\"\n",
    "    \n",
    "    grouped_patches = patch_col.find(\n",
    "        {\n",
    "            patch_group_column_name: patch_group[\"original_id\"]\n",
    "        }\n",
    "    )\n",
    "    all_patches_list = list(grouped_patches.clone())\n",
    "    all_patches_list.sort(key=lambda p: p[\"date\"])\n",
    "\n",
    "    return all_patches_list\n",
    "\n",
    "\n",
    "def get_comments_in_group(\n",
    "        level: int,\n",
    "        patch_group_id: str\n",
    ") -> Cursor:\n",
    "    \n",
    "    patch_group_column_name = f\"change{level}\"\n",
    "    comment_col = db[\"patchwork_comment\"]\n",
    "    \n",
    "    grouped_comments = comment_col.find(\n",
    "                        {\n",
    "            patch_group_column_name: patch_group_id\n",
    "        }\n",
    "    )\n",
    "    all_comments_list = list(grouped_comments.clone())\n",
    "    all_comments_list.sort(key=lambda c: c[\"date\"])\n",
    "\n",
    "    return all_comments_list\n",
    "\n",
    "\n",
    "def prepare_code_review_data(\n",
    "    level: int,\n",
    "    patch_group: Cursor\n",
    ") -> dict:\n",
    "    \n",
    "    code_review_data = {\n",
    "        \"all_patches_list\": None,\n",
    "        \"all_comments_list\": None,\n",
    "        \"first_patch\": None,\n",
    "        \"last_patch\": None,\n",
    "        \"first_comment\": None,\n",
    "        \"last_comment\": None,\n",
    "    }\n",
    "\n",
    "    # get patches in group - sort by timestamp\n",
    "    all_patches_list = get_patches_in_group(\n",
    "        level=level,\n",
    "        patch_group=patch_group\n",
    "    )\n",
    "\n",
    "    # safe guard - in case no patches in the group\n",
    "    if len(all_patches_list) > 0:\n",
    "        code_review_data[\"all_patches_list\"] = all_patches_list\n",
    "\n",
    "        code_review_data[\"first_patch\"] = all_patches_list[0]\n",
    "        code_review_data[\"last_patch\"] = all_patches_list[-1]\n",
    "\n",
    "        # find comments in group - sort by timestamp\n",
    "        all_comments_list = get_comments_in_group(\n",
    "            level=level,\n",
    "            patch_group_id=patch_group[\"original_id\"]\n",
    "        )\n",
    "\n",
    "        # print(\"finish querying - start calculation\")\n",
    "\n",
    "        # safe guard - in case no comments were made\n",
    "        if len(all_comments_list) > 0:\n",
    "            \n",
    "            code_review_data[\"first_comment\"] = all_comments_list[0]\n",
    "            code_review_data[\"last_comment\"] = all_comments_list[-1]\n",
    "\n",
    "            code_review_data[\"all_comments_list\"] = all_comments_list\n",
    "\n",
    "    \n",
    "    return code_review_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_computation(\n",
    "    patch_group:dict,\n",
    "    all_patches_list: list,\n",
    "    all_comments_list: list,\n",
    "    first_patch: dict,\n",
    "    first_comment: dict,\n",
    "    last_comment: dict\n",
    ") -> dict:\n",
    "    # iterations\n",
    "    iterations = len(all_patches_list)\n",
    "\n",
    "    # intensity\n",
    "    # comments or discussion length\n",
    "    comments = len(all_comments_list) if all_comments_list is not None else 0\n",
    "\n",
    "    total_changed_files = 0\n",
    "    total_changed_lines = 0\n",
    "    changed_files_first = 0\n",
    "    changed_lines_first = 0\n",
    "    changed_files_last = 0\n",
    "    changed_lines_last = 0\n",
    "    incomplete_change_info = False\n",
    "\n",
    "    # individual submitters in grouped patches\n",
    "    individuals = set()\n",
    "\n",
    "    for i, patch in enumerate(all_patches_list):\n",
    "        # print(all_patches_list[0][\"code_diff\"])\n",
    "        (\n",
    "            changed_files,\n",
    "            changed_lines,\n",
    "            incomplete_change_info,\n",
    "        ) = parse_diff(diff_text=patch[\"code_diff\"])\n",
    "\n",
    "        total_changed_files += changed_files\n",
    "        total_changed_lines += changed_lines\n",
    "\n",
    "        # first version\n",
    "        if i == 0:\n",
    "            changed_files_first = changed_files\n",
    "            changed_lines_first = changed_lines\n",
    "\n",
    "        # last version\n",
    "        if i == len(all_patches_list) - 1:\n",
    "            changed_files_last = changed_files\n",
    "            changed_lines_last = changed_lines\n",
    "\n",
    "        # patch author\n",
    "        individuals.add(patch[\"submitter_individual\"])\n",
    "\n",
    "    # code churn\n",
    "    changed_lines_avg = total_changed_lines / len(all_patches_list)\n",
    "\n",
    "    # files changed\n",
    "    changed_files_avg = total_changed_files / len(all_patches_list)\n",
    "\n",
    "    # participation\n",
    "    # authors\n",
    "    authors = len(individuals)\n",
    "\n",
    "    # reviewers - commentators that are not authors\n",
    "    commentators = []\n",
    "    if all_comments_list is not None:\n",
    "        commentators = set(\n",
    "            [\n",
    "                comment[\"submitter_individual\"]\n",
    "                for comment in all_comments_list\n",
    "                if comment[\"submitter_individual\"]\n",
    "                not in individuals\n",
    "            ]\n",
    "        )\n",
    "    reviewers = len(commentators)\n",
    "\n",
    "    # time\n",
    "    # first response\n",
    "    response_time_seconds = (\n",
    "        (first_comment[\"date\"] - first_patch[\"date\"]).total_seconds()\n",
    "        if first_comment is not None\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    # finalization - first patch until last comment\n",
    "    # suggested by Rigby and Bird\n",
    "    finalizing_time_seconds = (\n",
    "        (last_comment[\"date\"] - first_patch[\"date\"]).total_seconds()\n",
    "        if last_comment is not None\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    # result per group\n",
    "    is_accepted = True if patch_group[\"is_accepted\"] else False\n",
    "\n",
    "    return {\n",
    "        \"reviewers\": reviewers,\n",
    "        \"authors\": authors,\n",
    "        \"comments\": comments,\n",
    "        \"iterations\": iterations,\n",
    "        \"changed_lines_avg\": changed_lines_avg,\n",
    "        \"changed_lines_first\": changed_lines_first,\n",
    "        \"changed_lines_last\": changed_lines_last,\n",
    "        \"changed_files_avg\": changed_files_avg,\n",
    "        \"changed_files_first\": changed_files_first,\n",
    "        \"changed_files_last\": changed_files_last,\n",
    "        \"incomplete_change_info\": incomplete_change_info,\n",
    "        \"response_time\": response_time_seconds / 60 / 60,\n",
    "        \"finalizing_time\": finalizing_time_seconds / 60 / 60,\n",
    "        \"is_accepted\": is_accepted,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code review metrics calculation - per patch group (change1 and change2)\n",
    "patch_group_info_list = []\n",
    "\n",
    "def append_list_structure(patch_group_info_list:list, entry: dict):\n",
    "\n",
    "    # ensure all columns are available\n",
    "    assert \"project_original_id\" in entry\n",
    "    assert \"patch_group_original_id\" in entry\n",
    "    assert \"reviewer_count\" in entry\n",
    "    assert \"author_count\" in entry\n",
    "    assert \"comment_count\" in entry\n",
    "    assert \"iteration_count\" in entry\n",
    "    assert \"changed_lines_avg\" in entry\n",
    "    assert \"changed_lines_first\" in entry\n",
    "    assert \"changed_lines_last\" in entry\n",
    "    assert \"changed_files_avg\" in entry\n",
    "    assert \"changed_files_first\" in entry\n",
    "    assert \"changed_files_last\" in entry\n",
    "    assert \"incomplete_change_info\" in entry\n",
    "    assert \"response_time\" in entry\n",
    "    assert \"finalizing_time\" in entry\n",
    "    assert \"is_accepted\" in entry\n",
    "\n",
    "    patch_group_info_list.append(entry)\n",
    "\n",
    "    return patch_group_info_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start query\")\n",
    "for level in range(1, 3):\n",
    "\n",
    "    for project in selected_projects:\n",
    "\n",
    "        data_filename, description_filename = generate_file_names(\n",
    "            project=project, level=level\n",
    "        )\n",
    "\n",
    "        if Path(data_filename).is_file():\n",
    "            print(project, level, data_filename, \"results already exist, skipping\")\n",
    "\n",
    "        else:\n",
    "            total_group_executed = 0\n",
    "            patch_group_info_list = []\n",
    "\n",
    "            # get patch groups\n",
    "            patch_groups = get_patch_groups(level=level, project=project)\n",
    "\n",
    "            print(\"# of total groups: \", len(list(patch_groups.clone())))\n",
    "\n",
    "            # running through grouped patches (including patches identified as individual)\n",
    "            for patch_group in patch_groups:\n",
    "                print(patch_group[\"original_id\"])\n",
    "\n",
    "                # prepare code review dataset in patch group from database\n",
    "                code_review_data = prepare_code_review_data(\n",
    "                    level=level,\n",
    "                    patch_group=patch_group\n",
    "                )\n",
    "\n",
    "                if code_review_data[\"all_patches_list\"] is not None:\n",
    "\n",
    "                    # metrics computation\n",
    "                    metric_results = metrics_computation(\n",
    "                        patch_group=patch_group,\n",
    "                        all_patches_list=code_review_data[\"all_patches_list\"],\n",
    "                        all_comments_list=code_review_data[\"all_comments_list\"],\n",
    "                        first_patch=code_review_data[\"first_patch\"],\n",
    "                        first_comment=code_review_data[\"first_comment\"],\n",
    "                        last_comment=code_review_data[\"last_comment\"]\n",
    "                    )\n",
    "\n",
    "                    patch_group_info_list = append_list_structure(\n",
    "                        patch_group_info_list=patch_group_info_list,\n",
    "                        entry={\n",
    "                            \"project_original_id\": project,\n",
    "                            \"patch_group_original_id\": patch_group[\"original_id\"],\n",
    "                            \"reviewer_count\": metric_results[\"reviewers\"],\n",
    "                            \"author_count\": metric_results[\"authors\"],\n",
    "                            \"comment_count\": metric_results[\"comments\"],\n",
    "                            \"iteration_count\": metric_results[\"iterations\"],\n",
    "                            \"changed_lines_avg\": metric_results[\"changed_lines_avg\"],\n",
    "                            \"changed_lines_first\": metric_results[\"changed_lines_first\"],\n",
    "                            \"changed_lines_last\": metric_results[\"changed_lines_last\"],\n",
    "                            \"changed_files_avg\": metric_results[\"changed_files_avg\"],\n",
    "                            \"changed_files_first\": metric_results[\"changed_files_first\"],\n",
    "                            \"changed_files_last\": metric_results[\"changed_files_last\"],\n",
    "                            \"incomplete_change_info\":metric_results[\"incomplete_change_info\"],\n",
    "                            \"response_time\": metric_results[\"response_time\"],\n",
    "                            \"finalizing_time\": metric_results[\"finalizing_time\"],\n",
    "                            \"is_accepted\": metric_results[\"is_accepted\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    # print(\"finish calculation\")\n",
    "\n",
    "                    total_group_executed += 1\n",
    "\n",
    "                # test run circuit breaker\n",
    "                if test_run and total_group_executed > 1000:\n",
    "                    break\n",
    "\n",
    "            # export data set once per project\n",
    "            export_dataset(\n",
    "                patch_group_info_list=patch_group_info_list,\n",
    "                project=project,\n",
    "                level=level\n",
    "            )\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis and Visualization\n",
    "- Data cleaning - Negative response time and finalizing time are remove from timestamp calculation (incomplete data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_counting_metrics_df = pd.DataFrame()\n",
    "concat_time_metrics_df = pd.DataFrame()\n",
    "\n",
    "# calculate cleaned version of data description\n",
    "for level in range(1, 3):\n",
    "    for project in selected_projects:\n",
    "\n",
    "        metrics = [\n",
    "            \"reviewer_count\",\n",
    "            \"author_count\",\n",
    "            \"comment_count\",\n",
    "            \"iteration_count\",\n",
    "            \"changed_lines_avg\",\n",
    "            \"changed_files_avg\",\n",
    "            \"changed_lines_last\",\n",
    "            \"changed_files_last\",\n",
    "            \"response_time\",\n",
    "            \"finalizing_time\",\n",
    "            \"is_accepted\",\n",
    "        ]\n",
    "\n",
    "        data_filename, _ = generate_file_names(\n",
    "            project=project,\n",
    "            level=level,\n",
    "            cleaned=False\n",
    "        )\n",
    "\n",
    "        assert Path(data_filename).is_file()\n",
    "        print(\"cleaning data in:\", data_filename)\n",
    "\n",
    "        cleaned_description_list = []\n",
    "        data_df = pd.read_csv(data_filename)\n",
    "\n",
    "        for metric in metrics:\n",
    "            \n",
    "            # apply filter to remove negative values\n",
    "            if metric in [\"response_time\", \"finalizing_time\"]:\n",
    "                target_metric = data_df[data_df[metric] >0][metric]\n",
    "            else:\n",
    "                target_metric = data_df[metric]\n",
    "\n",
    "            if metric != \"is_accepted\":\n",
    "                cleaned_description_list.append({\n",
    "                    \"metric\": metric,\n",
    "                    \"count\": len(target_metric),\n",
    "                    \"mean\": np.mean(target_metric),\n",
    "                    \"std\": np.std(target_metric),\n",
    "                    \"min\": min(target_metric),\n",
    "                    \"25%\": np.percentile(target_metric, 25),\n",
    "                    \"50%\": np.percentile(target_metric, 50),\n",
    "                    \"75%\": np.percentile(target_metric, 75),\n",
    "                    \"max\": max(target_metric)\n",
    "                })\n",
    "            else:\n",
    "                cleaned_description_list.append({\n",
    "                    \"metric\": metric,\n",
    "                    \"count\": len(target_metric),\n",
    "                    \"mean\": sum(target_metric),\n",
    "                    \"std\": None,\n",
    "                    \"min\": None,\n",
    "                    \"25%\": None,\n",
    "                    \"50%\": None,\n",
    "                    \"75%\": None,\n",
    "                    \"max\": None\n",
    "                })\n",
    "        \n",
    "        cleaned_description_df = pd.DataFrame(cleaned_description_list)\n",
    "        \n",
    "        _, cleaned_describe_filename = generate_file_names(\n",
    "            project=project,\n",
    "            level=level,\n",
    "            cleaned=True\n",
    "        )\n",
    "\n",
    "        cleaned_description_df.to_csv(cleaned_describe_filename, index=False)\n",
    "\n",
    "        print(\"concatenating data from:\", data_filename)\n",
    "        data_df[\"level\"] = f\"change-{level}\"\n",
    "        \n",
    "        # rename project\n",
    "        data_df[\"project_original_id\"] = data_df[\"project_original_id\"].replace(\n",
    "            project, project_name[project]\n",
    "        )\n",
    "        \n",
    "        # seperate data frame for counting metrics\n",
    "        data_df[\"log_comment_count\"] = np.log10(data_df[\"comment_count\"])\n",
    "        data_df[\"log_changed_lines_avg\"] = np.log10(data_df[\"changed_lines_avg\"])\n",
    "        data_df[\"log_changed_files_avg\"] = np.log10(data_df[\"changed_files_avg\"])\n",
    "\n",
    "        concat_counting_metrics_df = pd.concat([\n",
    "            concat_counting_metrics_df,\n",
    "            data_df.loc[:, ~data_df.columns.isin([\"response_time\", \"finalizing_time\"])]\n",
    "        ], axis=0)\n",
    "        \n",
    "        # seperate data frame for time metrics\n",
    "        time_df = data_df.loc[:, data_df.columns.isin([\n",
    "            \"project_original_id\",\n",
    "            \"patch_group_original_id\",\n",
    "            \"level\",\n",
    "            \"response_time\",\n",
    "            \"finalizing_time\"\n",
    "        ])]\n",
    "\n",
    "        # only take entries with non-negative time metrics\n",
    "        time_df = time_df[(time_df[\"response_time\"] > 0) & (time_df[\"finalizing_time\"] > 0)]\n",
    "\n",
    "        time_df[\"log_response_time\"] = np.log10(time_df[\"response_time\"])\n",
    "        time_df[\"log_finalizing_time\"] = np.log10(time_df[\"finalizing_time\"])\n",
    "\n",
    "        concat_time_metrics_df = pd.concat([\n",
    "            concat_time_metrics_df,\n",
    "            time_df.loc[:, ~time_df.columns.isin([\"response_time\", \"finalizing_time\"])]\n",
    "        ], axis=0)\n",
    "\n",
    "print(\"total normal metric dataframe size:\", concat_counting_metrics_df.shape)\n",
    "print(\"total time metric dataframe size:\", concat_time_metrics_df.shape)\n",
    "\n",
    "# melt time metrics to compare with violin plot\n",
    "concat_time_metrics_df = pd.melt(\n",
    "    concat_time_metrics_df,\n",
    "    id_vars=[\"project_original_id\", \"patch_group_original_id\", \"level\"],\n",
    "    var_name=\"time_metric\",\n",
    "    value_name=\"time_hr\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_counting_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_time_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export violin plots for counting metrics\n",
    "normal_metrics = [\n",
    "    \"reviewer_count\",\n",
    "    \"author_count\",\n",
    "    \"comment_count\",\n",
    "    \"log_comment_count\",\n",
    "    \"iteration_count\",\n",
    "    \"log_changed_lines_avg\",\n",
    "    \"log_changed_files_avg\",\n",
    "]\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for metric in normal_metrics:\n",
    "    sns.violinplot(\n",
    "        x=\"project_original_id\",\n",
    "        y=metric,\n",
    "        hue=\"level\",\n",
    "        data=concat_counting_metrics_df[concat_counting_metrics_df[metric] > 0],\n",
    "        palette=\"Pastel1\"\n",
    "    )\n",
    "    \n",
    "    plt.xlabel(\"project\") \n",
    "    plt.savefig(f\"output/plot_{metric}.pdf\")\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot change-1 for time metrics \n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = sns.violinplot(\n",
    "    x=\"project_original_id\",\n",
    "    y=\"time_hr\",\n",
    "    hue=\"time_metric\",\n",
    "    split=True,\n",
    "    scale_hue=False,\n",
    "    data=concat_time_metrics_df[concat_time_metrics_df[\"level\"] ==\"change-1\"],\n",
    "    palette=\"Pastel1\",\n",
    "    inner=None,\n",
    "    linewidth=1\n",
    ")\n",
    "sns.pointplot(\n",
    "    x=\"project_original_id\", \n",
    "    y=\"time_hr\",\n",
    "    hue=\"time_metric\",\n",
    "    data=concat_time_metrics_df[concat_time_metrics_df[\"level\"] ==\"change-1\"],\n",
    "    estimator=median,\n",
    "    linestyles=\"\",\n",
    "    palette=\"Pastel1\",\n",
    "    scale=0.5,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# only keep  legends for median\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "plt.legend(\n",
    "    h[2:4],\n",
    "    [\"Median of response time\", \"Median of code review time\"],\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=2,\n",
    "    borderaxespad=0.\n",
    ")\n",
    "   \n",
    "sns.move_legend(\n",
    "    ax,\n",
    "    \"lower center\",\n",
    "    bbox_to_anchor=(.5, 1),\n",
    "    ncol=3,\n",
    "    title=None, \n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# customized scale\n",
    "plt.yticks(\n",
    "    [-1.78, 0, 1.38, 2.22, 2.86, 3.94],\n",
    "    [\"1min\", \"1hr\", \"1day\", \"1week\", \"1month\", \"1year\"]\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Response and Code Review Time\")\n",
    "plt.xlabel(\"Project\")\n",
    "plt.savefig(f\"output/plot_time_metrics.pdf\")\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis--Mwly1am",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e837c235438718a88dd4ad62ca6592400975752d7da9a43cd8d76086cd8e1a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
